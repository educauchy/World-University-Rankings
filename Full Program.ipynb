{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coding=utf-8\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import geopandas, geoplot, random, re, scipy\n",
    "from bs4 import BeautifulSoup as BS\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.pyplot import figure, savefig\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "\n",
    "font = {'size': 16}\n",
    "matplotlib.rc('font', **font)\n",
    "\n",
    "rankings = ['THE', 'QS', 'CWUR', 'ARWU']\n",
    "countries = {\n",
    "    'AG': 'Argentina', 'AU': 'Austria', 'AUS': 'Australia', 'BE': 'Belgium', 'BEL': 'Belarus', 'BZ': 'Brazil',\n",
    "    'CA': 'Canada', 'CH': 'China', 'CHI': 'Chile', 'COL': 'Colombia', 'CZ': 'Czech', 'DN': 'Denmark',\n",
    "    'EG': 'Egypt', 'ES': 'Estonia', 'FI': 'Finland', 'FR': 'France', 'GE': 'Germany', 'GR': 'Greece',\n",
    "    'IN': 'India', 'ID': 'Indonesia', 'IR': 'Ireland', 'IRN': 'Iran', 'IT': 'Italy', 'IS': 'Izrael',\n",
    "    'JP': 'Japan', 'KO': 'Korea', 'KZ': 'Kazakhstan', 'LE': 'Lebanon', 'MA': 'Malaysia', 'ME': 'Mexico',\n",
    "    'NE': 'Netherlands', 'NO': 'Norway', 'NZ': 'New Zealand', 'PH': 'Philippines', 'PAK': 'Pakistan',\n",
    "    'POL': 'Poland', 'POR': 'Portugal', 'RU': 'Russia', 'SA': 'South Africa', 'SAU': 'Saudi Arabia',\n",
    "    'SG': 'Singapore', 'SP': 'Spain', 'SW': 'Sweden', 'TH': 'Thailand', 'UA': 'Ukraine',\n",
    "    'UAE': 'United Arab Emirates', 'UK': 'United Kingdom', 'US': 'United States of America'\n",
    "}\n",
    "\n",
    "media_dir = 'Media/'\n",
    "EDA_dir = 'Media/EDA/'\n",
    "rankings_dir = 'Media/Rankings'\n",
    "\n",
    "inputs_all = list(map(str, list(range(1, 57))))\n",
    "inputs_all.remove('47')\n",
    "\n",
    "edu = list(map(str, list(range(1, 10))))\n",
    "science = list(map(str, list(range(10, 21))))\n",
    "staff = list(map(str, list(range(21, 30))))\n",
    "inter = list(map(str, list(range(30, 39))))\n",
    "infra = list(map(str, list(range(39, 47))))\n",
    "fin = list(map(str, list(range(48, 57))))\n",
    "\n",
    "\n",
    "inputs = ['1.1', '1', '9', '2.1', '2.2', '2.3', '2.4', '2.5', '2.6', '2.7', '2.16', '13', '14', '3.1', '3.2', \n",
    "          '3.8', '3.9', '35', '4.1', '4.3', '48', '5.1', '5.6', '40', '41', '42', '46', '6.1', '6.2', '6.4', '28',\n",
    "         '2.1_2_3', '2.4_5_6', '3.1_2', '6.1_2', '13_14', '40_41_42']\n",
    "inputs_grouped = ['1.1', '1', '9', '2.7', '2.16', '3.8', '3.9', '35', '4.1', '4.3', '48',\n",
    "            '5.1', '5.6', '46', '6.4', '28', '2.1_2_3', '2.4_5_6', '3.1_2', '6.1_2', '13_14', '40_41_42']\n",
    "outputs = ['E.1', 'E.2', 'E.3', 'E.4', 'E.5']\n",
    "\n",
    "def set_rank(rank_range):\n",
    "    \"\"\"\n",
    "    Set university rank if it is defined as range, but not a single value\n",
    "    \n",
    "    Parameters:\n",
    "    rank_range (str): Consists university rank. Two formats: \"a-b\" or \"c+\", where a, b, c are integers and a < b\n",
    "    \n",
    "    Return\n",
    "    int: University rank as an integer\n",
    "    \"\"\"\n",
    "    \n",
    "    range_min_max = re.search('(\\d+)?-?(\\d+)?\\+?', rank_range)\n",
    "\n",
    "    if range_min_max[2] is None:\n",
    "        return int(range_min_max[1])\n",
    "    else:\n",
    "        rank = random.randint( int(range_min_max[1]), int(range_min_max[2]) )\n",
    "        return int(rank)\n",
    "    \n",
    "def kendall_w(data):\n",
    "    \"\"\"\n",
    "    Calculate and return Kendall's coefficient of concordance\n",
    "    \n",
    "    Parameters\n",
    "    data (Pandas dataframe): Dataframe of data\n",
    "    \n",
    "    Return\n",
    "    int: W coefficient\n",
    "    \"\"\"\n",
    "    \n",
    "    m = 4\n",
    "    n = len(data)\n",
    "    Ri = data.sum(axis = 1)\n",
    "    T = 0\n",
    "    for ranking in data:\n",
    "        vc = data[ranking].value_counts()\n",
    "        d = vc[vc > 1]\n",
    "        t = np.sum(list(map(lambda t: t ** 3 - t, d)))\n",
    "        T = T + t\n",
    "    \n",
    "    W = (12 * np.sum(Ri) - 3 * m ** 2 * n * (n + 1) ** 2) / (m ** 2 * n * (n ** 2 - 1) - m * T)\n",
    "    rS = (m * W - 1) / (m - 1)\n",
    "\n",
    "    return (T, W, rS)\n",
    "\n",
    "url = 'http://indicators.miccedu.ru/monitoring/index.php?m=vpo'\n",
    "r = requests.get(url)\n",
    "r.encoding = r.apparent_encoding\n",
    "page = BS(r.text, 'html.parser')\n",
    "\n",
    "columns = []\n",
    "uni_id_list = []\n",
    "uni = []\n",
    "data = pd.DataFrame(data = [[0, 1, 2, 3, 4]],\n",
    "                    columns = ['uni_id', 'index', 'desc', 'dim', 'measure'])\n",
    "\n",
    "for state in page.select('p.MsoListParagraph a[href]'): # through regions\n",
    "    region_url = host + str(year) + '/' + state['href']\n",
    "    r = requests.get(region_url)\n",
    "    r.encoding = r.apparent_encoding\n",
    "    state_page = BS(r.content)\n",
    "    \n",
    "    for uni in state_page.select('.blockcontent tr td.inst a[href]'): # through unis\n",
    "        uni_id = int(uni['href'][12:])\n",
    "        uni.append(uni.get_text())\n",
    "        uni_id_list.append(uni_id)\n",
    "        uni_url = host + '_vpo/' + uni['href']\n",
    "        r = requests.get(uni_url)\n",
    "        r.encoding = r.apparent_encoding\n",
    "        uni_page = BS(r.content)\n",
    "                    \n",
    "        for indicator in uni_page.select('table#analis_dop tr'): # through the last table\n",
    "            fields = []\n",
    "            td_num = len(indicator.find_all('td'))\n",
    "            \n",
    "            if td_num == 4: # skip headings and not full rows\n",
    "                for td in indicator.select('td'):\n",
    "                    fields.append(td.get_text())\n",
    "                row = pd.DataFrame(data = [[uni_id, fields[0], fields[1], fields[2], fields[3]]],\n",
    "                                    columns = ['uni_id', 'index', 'desc', 'dim', 'measure'])\n",
    "                data = data.append(row)\n",
    "\n",
    "data = data.iloc[3:, :]\n",
    "data.set_index('uni_id', inplace = True)\n",
    "data.to_excel('russian_uni.xlsx', index = False)\n",
    "\n",
    "url = 'http://indicators.miccedu.ru/monitoring/_vpo/inst.php?id='\n",
    "unis = pd.read_excel('Data/Russian_Universities_Initial.xlsx')\n",
    "\n",
    "for index, uni in unis.iterrows():\n",
    "    r = requests.get(url + str(uni.Uni_Id))\n",
    "    r.encoding = r.apparent_encoding\n",
    "    page = BS(r.text, 'html.parser')\n",
    "    \n",
    "    \n",
    "    for indicator in page.select('table#analis_dop tr'): # through the last table\n",
    "        fields = []\n",
    "        td_num = len(indicator.find_all('td'))\n",
    "            \n",
    "        if td_num == 4: # skip headings and not full rows\n",
    "            not_valid = False\n",
    "            for ix, td in enumerate(indicator.select('td')):\n",
    "                if re.search('№', td.get_text()) or (ix == 2 and re.search('да', td.get_text())):\n",
    "                    not_valid = True\n",
    "                    break\n",
    "                else:\n",
    "                    fields.append(td.get_text())\n",
    "            \n",
    "            if not_valid == False:\n",
    "                unis.loc[index, str(fields[0])] = float(fields[3].replace(' ', '').replace(',', '.'))\n",
    "\n",
    "    for table in page.select('table.napde'):        \n",
    "        row = []\n",
    "        for ix, indicator in enumerate(table.select('td')): # through the last table\n",
    "            if ix in [0, 1, 2, 3]:\n",
    "                continue\n",
    "            else:\n",
    "                res = divmod(ix, 4)\n",
    "                if res[1] in [0, 3]:\n",
    "                    row.append(indicator.get_text())\n",
    "                    \n",
    "                if res[1] == 3:\n",
    "                    unis.loc[index, str(row[0])] = float(row[1].replace(' ', '').replace(',', '.'))\n",
    "                    row = []\n",
    "\n",
    "    # working with outpus\n",
    "    # there is an additional empty tbody before thead of the result table, so we cannot use BS\n",
    "    # use regex instead\n",
    "    Es = re.findall('(E\\.\\d)</td>', str(page))\n",
    "    output_values = re.findall('right center no-repeat;\\\">(\\d+(?:,\\d+)?)<', str(page))\n",
    "    income = re.findall('<span style=\\\"\\\">(\\d+(?:,\\d+)?)<', str(page))\n",
    "    output_values.insert(4, income[0])\n",
    "    \n",
    "    for ix, val in enumerate(output_values):\n",
    "        unis.loc[index, Es[ix]] = float(val.replace(',', '.'))\n",
    "        \n",
    "        \n",
    "unis['2.1_2_3'] = unis['2.1'] + unis['2.2'] + unis['2.3']\n",
    "unis['2.4_5_6'] = unis['2.4'] + unis['2.5'] + unis['2.6']\n",
    "unis['3.1_2'] = unis['3.1'] + unis['3.2']\n",
    "unis['6.1_2'] = unis['6.1'] + unis['6.2']\n",
    "unis['13_14'] = unis['13'] + unis['14']\n",
    "unis['40_41_42'] = (unis['40'] + unis['41'] + unis['42']) / 10000\n",
    "\n",
    "for index, university in unis.iterrows():\n",
    "    for ranking in ['THE', 'QS', 'CWUR', 'ARWU']:\n",
    "        value = unis.loc[unis.University == university[0], ranking]\n",
    "        if not (isinstance(value[index], int) or value[index] is None or isinstance( value[index], float)):\n",
    "            unis.loc[unis.University == university[0], ranking] = set_rank(value[index])\n",
    "            \n",
    "unis.to_excel('Data/Russian_Universities.xlsx', index = False)\n",
    "unis.to_csv('Data/Russian_Universities.csv', index = False)\n",
    "\n",
    "unis = pd.read_excel('Data/Russian_Universities.xlsx')\n",
    "data = pd.read_excel('Data/Russian_Universities_TS_Initial.xlsx')\n",
    "data.loc[(data.Year == 2020) & (data.Ranking == 'THE')].Rank = unis.THE\n",
    "data.loc[(data.Year == 2020) & (data.Ranking == 'QS')].Rank = unis.QS\n",
    "data.loc[(data.Year == 2020) & (data.Ranking == 'ARWU')].Rank = unis.ARWU\n",
    "data.loc[(data.Year == 2020) & (data.Ranking == 'CWUR')].Rank = unis.CWUR\n",
    "\n",
    "for index, row in data.iterrows():\n",
    "    rank = row[2] # rank\n",
    "    if not isinstance(rank, int) and not (rank is None) and not isinstance( rank, float):\n",
    "        data.loc[index, 'Rank'] = set_rank(rank)\n",
    "\n",
    "data.to_excel('Data/Russian_Universities_TS.xlsx', index = False)\n",
    "\n",
    "url = 'http://www.shanghairanking.com/ARWU2019.html'\n",
    "r = requests.get(url)\n",
    "page = BS(r.text, 'html.parser')\n",
    "\n",
    "data = pd.DataFrame(data = [[0, 1, 2, 3, 4, 5, 6, 7]],\n",
    "                    columns = ['Rank', 'Uni', 'Alumni', 'Award', 'HiCi', 'N&S', 'PUB', 'PCP'])\n",
    "\n",
    "for i, uni in enumerate(page.select('table#UniversityRanking tr')):\n",
    "    if i == 0:\n",
    "        continue\n",
    "    else:\n",
    "        fields = []\n",
    "        for j, indicator in enumerate(uni.select('td')):\n",
    "            if j in [0, 1, 5, 6, 7, 8, 9, 10]:\n",
    "                if j == 1:\n",
    "                    ind = (indicator.select('a'))[0].text\n",
    "                else:\n",
    "                    ind = indicator.text\n",
    "                fields.append(ind)\n",
    "        row = pd.DataFrame(data = [[fields[0], fields[1], fields[2], fields[3], fields[4], fields[5], fields[6], fields[7]]],\n",
    "                                    columns = ['Rank', 'Uni', 'Alumni', 'Award', 'HiCi', 'N&S', 'PUB', 'PCP'])\n",
    "        data = data.append(row)\n",
    "\n",
    "data.set_index('Rank', inplace = True)\n",
    "data.to_excel('Data/ARWU_Ranking_Full.xlsx')\n",
    "\n",
    "world = (pd.read_excel('Data/All_Universities_2020.xlsx')).iloc[:500, :29]\n",
    "uni = world.University\n",
    "world = world.set_index('University')\n",
    "world = world.dropna()\n",
    "\n",
    "world['Country'] = [countries[code] for code in world.loc[:, 'Country Code']]\n",
    "\n",
    "# Fill ranged ranks (101-150, 800-1000)\n",
    "for ranking in rankings:\n",
    "    for rank_i in range(len(world[ranking])):\n",
    "        rank = world[ranking][rank_i]\n",
    "        if isinstance(rank, str):\n",
    "            world.loc[:, ranking][rank_i] = set_rank(rank)\n",
    "            \n",
    "# Convert to ranks\n",
    "rdata = (world.reset_index())[rankings].rank(axis = 0, ascending = True)\n",
    "rdata['University'] = uni\n",
    "rdata = rdata.set_index('University')\n",
    "\n",
    "world.THE = rdata.THE\n",
    "world.QS = rdata.QS\n",
    "world.CWUR = rdata.CWUR\n",
    "world.ARWU = rdata.ARWU\n",
    "rdata.head()\n",
    "\n",
    "# All data\n",
    "corr_matrix = scipy.stats.spearmanr(world.loc[:, rankings])[0]\n",
    "sns.heatmap(corr_matrix, vmin = 0, vmax = 1, annot = True, xticklabels = rankings, yticklabels = rankings)\n",
    "plt.savefig(media_dir + 'spearman_corr.png', bbox_inches='tight')\n",
    "\n",
    "# 1-100 and 101-200\n",
    "f, axes = plt.subplots(1, 2, figsize = (16, 6))\n",
    "corr_matrix_100 = scipy.stats.spearmanr(world.loc[:, rankings][1:100])[0]\n",
    "corr_matrix_200 = scipy.stats.spearmanr(world.loc[:, rankings][101:200])[0]\n",
    "\n",
    "sns.heatmap(corr_matrix_100, vmin = 0, vmax = 1, annot = True, ax = axes[0], xticklabels = rankings, yticklabels = rankings)\n",
    "sns.heatmap(corr_matrix_200, vmin = 0, vmax = 1, annot = True, ax = axes[1], xticklabels = rankings, yticklabels = rankings)\n",
    "plt.savefig(media_dir + 'spearman_corr_1-100-200.png', bbox_inches='tight')\n",
    "\n",
    "rusuni = pd.read_excel('Data/Russian_Universities.xlsx')\n",
    "rusuni.dropna(inplace = True)\n",
    "rusuni.reset_index(drop = True, inplace = True)\n",
    "rusuni = rusuni.loc[:, inputs + outputs + rankings + ['University', 'Region']]\n",
    "rusuni.head()\n",
    "\n",
    "corr = rusuni.loc[:, inputs].corr()\n",
    "figure(figsize = (25, 25))\n",
    "sns.heatmap(corr, vmin = -1, vmax = 1, cmap = 'coolwarm', fmt=\".1f\")\n",
    "plt.savefig(media_dir + 'heatmap_inputs.png', bbox_inches='tight')\n",
    "\n",
    "corr = rusuni.loc[:, inputs_grouped].corr()\n",
    "figure(figsize = (25, 25))\n",
    "sns.heatmap(corr, vmin = -1, vmax = 1, cmap = 'coolwarm', fmt=\".1f\")\n",
    "plt.savefig(media_dir + 'heatmap_inputs_grouped.png', bbox_inches='tight')\n",
    "\n",
    "# Data exploration before PCA\n",
    "f, axes = plt.subplots(1, 2, figsize = (16, 6))\n",
    "positive_cor = ['2.7', '5.1', '6.1_2', '6.4', '35', '40_41_42', '48']\n",
    "negative_cor = ['1', '2.1_2_3', '2.4_5_6', '3.8', '3.9', '4.3', '5.6', '9', '28']\n",
    "output_cor_shrink = ['E.1', 'E.2', 'E.4', 'E.5']\n",
    "output_cor = ['E.1', 'E.2', 'E.3', 'E.4', 'E.5']\n",
    "\n",
    "corr_matrix_positive = rusuni.loc[:, positive_cor].corr()\n",
    "corr_matrix_negative = rusuni.loc[:, negative_cor].corr()\n",
    "\n",
    "sns.heatmap(corr_matrix_positive, vmin = 0, vmax = 1, annot = True, ax = axes[0], cmap = 'coolwarm', fmt=\".1f\")\n",
    "sns.heatmap(corr_matrix_negative, vmin = 0, vmax = 1, annot = True, ax = axes[1], cmap = 'coolwarm', fmt=\".1f\")\n",
    "plt.savefig(media_dir + 'spearman_corr_strong_weak.png', bbox_inches='tight')\n",
    "\n",
    "print('Number of variables:', len(corr) - len(positive_cor) - len(negative_cor) + 3)\n",
    "\n",
    "corr = ['1.1', '13_14', '2.16', '3.1_2', '4.1', '46']\n",
    "corr_matrix = rusuni.loc[:, corr].corr()\n",
    "sns.heatmap(corr_matrix, vmin = 0, vmax = 1, annot = True, cmap = 'coolwarm', fmt=\".1f\")\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca_pos = PCA(n_components = 2)\n",
    "pca_pos.fit(rusuni.loc[:, positive_cor].T)\n",
    "PC1 = np.round(pca_pos.components_[0], 4)\n",
    "# print('Explained variance ration positive: ', pca_pos.explained_variance_ratio_)\n",
    "print('PC1 explained:', pca_pos.explained_variance_ratio_[0])\n",
    "\n",
    "\n",
    "pca_neg = PCA(n_components = 2)\n",
    "pca_neg.fit(rusuni.loc[:, negative_cor].T)\n",
    "PC2 = np.round(pca_neg.components_[0], 4)\n",
    "PC3 = np.round(pca_neg.components_[1], 4)\n",
    "# print('Explained variance ration negative: ', pca_neg.explained_variance_ratio_)\n",
    "print('PC2, PC3 explained:', pca_neg.explained_variance_ratio_[0:2])\n",
    "\n",
    "\n",
    "pca_out = PCA(n_components = 2)\n",
    "pca_out.fit(rusuni.loc[:, output_cor].T)\n",
    "PC4 = np.round(pca_out.components_[0], 4)\n",
    "# print('Explained variance ration negative: ', pca_neg.explained_variance_ratio_)\n",
    "print('PC4 explained:', pca_out.explained_variance_ratio_[0])\n",
    "\n",
    "pca_out = PCA(n_components = 2)\n",
    "pca_out.fit(rusuni.loc[:, output_cor_shrink].T)\n",
    "PC5 = np.round(pca_out.components_[0], 4)\n",
    "# print('Explained variance ration negative: ', pca_neg.explained_variance_ratio_)\n",
    "print('PC5 explained:', pca_out.explained_variance_ratio_[0])\n",
    "\n",
    "rusuni.loc[:, 'INPUT1'] = PC1\n",
    "rusuni.loc[:, 'INPUT2'] = PC2\n",
    "rusuni.loc[:, 'INPUT3'] = PC3\n",
    "rusuni.loc[:, 'OUTPUT_FULL'] = PC4\n",
    "rusuni.loc[:, 'OUTPUT_SHRINK'] = PC5\n",
    "\n",
    "rusuni.to_csv('Data/Russian_Universities.csv', index = False)\n",
    "\n",
    "corr = rusuni.loc[:, outputs].corr()\n",
    "figure(figsize = (10, 8))\n",
    "sns.heatmap(corr, annot = True, vmin = -1, vmax = 1, cmap = 'coolwarm', fmt=\".1f\")\n",
    "plt.savefig(media_dir + 'heatmap_outputs.png', bbox_inches='tight')\n",
    "\n",
    "for input in inputs:\n",
    "    figure(figsize = (20, 10))\n",
    "    plt.plot(rusuni.University, rusuni[input])\n",
    "    plt.title(input)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.savefig(EDA_dir + 'Distributions/' + input + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "for output in outputs:\n",
    "    figure(figsize = (20, 10))\n",
    "    plt.plot(rusuni.University, rusuni[output])\n",
    "    plt.title(output)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(EDA_dir + 'Distributions/' + output + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "figure(figsize = (20, 10))\n",
    "plt.plot(rusuni.University, rusuni['3.1_2'], 'o')\n",
    "plt.xlabel('University')\n",
    "plt.ylabel('Share of foreign students, %')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.savefig(EDA_dir + '/3-1_2_explained.png', bbox_inches='tight')\n",
    "\n",
    "figure(figsize = (20, 10))\n",
    "plt.plot(rusuni.University, rusuni['2.1'], 'o')\n",
    "plt.plot(rusuni.University, rusuni['2.2'], 'o')\n",
    "plt.plot(rusuni.University, rusuni['2.3'], 'o')\n",
    "plt.legend(['Web of Science', 'Scopus', 'RSCI'])\n",
    "plt.xlabel('University')\n",
    "plt.ylabel('Number of citations per 100 faculty members')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.savefig(EDA_dir + '/2-1_2_3_explained.png', bbox_inches='tight')\n",
    "\n",
    "figure(figsize = (20, 10))\n",
    "plt.plot(rusuni.University, rusuni['2.4'], 'o')\n",
    "plt.plot(rusuni.University, rusuni['2.5'], 'o')\n",
    "plt.plot(rusuni.University, rusuni['2.6'], 'o')\n",
    "plt.legend(['Web of Science', 'Scopus', 'RSCI'])\n",
    "plt.xlabel('University')\n",
    "plt.ylabel('Number of publications per 100 faculty members')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.savefig(EDA_dir + '/2-4_5_6_explained.png', bbox_inches='tight')\n",
    "\n",
    "figure(figsize = (20, 10))\n",
    "plt.plot(rusuni.University, rusuni['40'] / 10000, 'o')\n",
    "plt.plot(rusuni.University, rusuni['41'] / 10000, 'o')\n",
    "plt.plot(rusuni.University, rusuni['42'] / 10000, 'o')\n",
    "plt.legend(['Educational and laboratory rooms', 'Research department rooms', 'Dormitories'])\n",
    "plt.xlabel('University')\n",
    "plt.ylabel('Square, ha')\n",
    "plt.xticks(rotation = 90)\n",
    "plt.savefig(EDA_dir + '/40_41_42_explained.png', bbox_inches='tight')\n",
    "\n",
    "for input in inputs:\n",
    "    figure(figsize = (20, 10))\n",
    "    sns.boxplot(rusuni[input])\n",
    "    plt.title(input)\n",
    "    plt.xticks(rotation = 90)\n",
    "    plt.savefig(EDA_dir + 'BoxPlots/' + input + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "for output in outputs:\n",
    "    figure(figsize = (20, 10))\n",
    "    sns.boxplot(rusuni[output])\n",
    "    plt.title(output)\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.savefig(EDA_dir + '/BoxPlots/' + output + '.png', bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "ts = pd.read_excel('Data/Russian_Universities_TS.xlsx')\n",
    "QS = ts.loc[(ts.University.isin(rusuni.University)) & (ts.Ranking == 'QS')]\n",
    "QS.dropna(inplace = True)\n",
    "\n",
    "fig, axes = plt.subplots(4, 3,figsize = (16, 14), constrained_layout = True)\n",
    "\n",
    "k = 0\n",
    "for i, row in enumerate(axes):\n",
    "    for j, col in enumerate(row):\n",
    "        if k < len(rusuni.University):\n",
    "            uni_name = rusuni.University[k]\n",
    "            u = QS.loc[QS.University == uni_name]\n",
    "            u.reset_index(drop = True, inplace = True)\n",
    "            axes[i, j].plot(u.Year, u.Rank)\n",
    "            axes[i, j].set_xticks(u.Year)\n",
    "            axes[i, j].set_xticklabels(u.Year, fontsize = 12)\n",
    "            axes[i, j].set_title(uni_name)\n",
    "            axes[i, j].set_ylabel('Rank')\n",
    "\n",
    "            \n",
    "            for ix, _ in enumerate(u.Year):\n",
    "                axes[i, j].text(u.Year[ix], int(u.Rank[ix]) - 3, int(u.Rank[ix]))\n",
    "        k = k + 1\n",
    "\n",
    "axes[-1, -1].axis('off')\n",
    "plt.savefig(media_dir + 'Russian_TS.png')\n",
    "\n",
    "rusuni = pd.read_excel('Data/Russian_Universities.xlsx')\n",
    "rusuni.dropna(inplace = True)\n",
    "rusuni.reset_index(drop = True, inplace = True)\n",
    "rusuni = rusuni.loc[:, inputs + outputs + rankings + ['University', 'Region']]\n",
    "rusuni.head(15)\n",
    "\n",
    "# number of universities in each ranking\n",
    "THE_len = 1397\n",
    "QS_len = 1002\n",
    "CWUR_len = 2000\n",
    "ARWU_len = 1000\n",
    "\n",
    "rusuni['THE_eff'] = (THE_len - rusuni.THE) / THE_len\n",
    "rusuni['QS_eff'] = (QS_len - rusuni.QS) / QS_len\n",
    "rusuni['CWUR_eff'] = (CWUR_len - rusuni.CWUR) / CWUR_len\n",
    "rusuni['ARWU_eff'] = (ARWU_len - rusuni.ARWU) / ARWU_len\n",
    "rusuni['SFA_eff'] = [0.9934, 0.9934, 0.9961, 0.9975, 0.9958, 0.9858, 0.9946, 0.9941, 0.9953, 0.9933, 0.9965]\n",
    "\n",
    "rusuni.head(11)\n",
    "\n",
    "print('MAE THE:', mae(rusuni.SFA_eff, rusuni.THE_eff))\n",
    "print('MAE QS:', mae(rusuni.SFA_eff, rusuni.QS_eff))\n",
    "print('MAE ARWU:', mae(rusuni.SFA_eff, rusuni.ARWU_eff))\n",
    "print('MAE CWUR:', mae(rusuni.SFA_eff, rusuni.CWUR_eff))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
